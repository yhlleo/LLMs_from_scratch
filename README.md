# LLMs_from_scratch
Learning records for building a large language model from scratch

### Records

 - **Section 1**:

[x] Understanding word embeddings

[x] Tokenizing text

[x] Converting tokens into token IDs

[x] Adding special context tokens

[x] Byte pair encoding (TODO: more details)

[x] Data sampling with a sliding window

[x] Creating token embeddings

[x] Encoding word positions

 - **Section 2**:

[x] Capturing data dependencies with attention mechanisms

[x] Implementing self-attention with trainable weights

