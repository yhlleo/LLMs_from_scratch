{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd2f3466-a425-4ce9-b63b-0bb8e28e4af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "import tiktoken\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b8bb1ca-a683-485b-b9f0-e7c9deb87196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codes.gpt_model import GPTModel\n",
    "from codes.utils import generate, text_to_token_ids, token_ids_to_text\n",
    "from codes.solver import train_model_simple\n",
    "from codes.losses import calc_loss_loader\n",
    "\n",
    "from codes.configs import gpt2_small_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d7534b-0a55-43c1-b556-dafc589e4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"Bellow is an instruction that describe a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input: \\n{entry['input']}\" if entry['input'] else \"\"\n",
    "\n",
    "    return instruction_text + input_text\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "\n",
    "        self.encoded_texts = []\n",
    "        for entry in data:\n",
    "            instruction_plus_input = format_input(entry)\n",
    "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
    "            full_text = instruction_plus_input + response_text\n",
    "            self.encoded_texts.append(tokenizer.encode(full_text))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c273bbec-7125-4c37-82d9-ecf6ae004ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch,\n",
    "    pad_token_id=50256,\n",
    "    ignore_index=-100,\n",
    "    allowed_max_length=None,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    batch_max_length = max([len(item)+1 for item in batch])\n",
    "\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (batch_max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        mask =  targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f17db3a-7699-4e0e-97e1-5f388c30b64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n"
     ]
    }
   ],
   "source": [
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "            fout.write(text_data)\n",
    "    #else:\n",
    "    #    with open(file_path, \"r\", encoding=\"utf-8\") as fin:\n",
    "    #        text_data = fin.read()\n",
    "\n",
    "    with open(file_path, \"r\") as fin:\n",
    "        data = json.load(fin)\n",
    "\n",
    "    return data\n",
    "\n",
    "file_path = \"ch07/instruction-data.json\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4adda007-e0c1-45d6-82fb-44466b41ae3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: 935\n",
      "Test data: 110\n",
      "Validation data: 55\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.1)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion:train_portion+test_portion]\n",
    "val_data = data[train_portion+test_portion:]\n",
    "\n",
    "print(f\"Training data: {len(train_data)}\")\n",
    "print(f\"Test data: {len(test_data)}\")\n",
    "print(f\"Validation data: {len(val_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "122fb423-c3f0-4cd9-992e-3547a0028887",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "580ab70c-d894-4b41-bedf-bb8d8853003b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    collate_fn=customized_collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2a18930-b39e-4a6c-b841-392db5082872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 50257, 'context_length': 1024, 'emb_dim': 768, 'num_heads': 12, 'n_layers': 12, 'drop_rate': 0.0, 'qkv_bias': True}\n"
     ]
    }
   ],
   "source": [
    "BASE_CONFIG = gpt2_small_config()\n",
    "print(BASE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8fc0f87-264f-4a30-9343-588e1ffe747c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trans_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiheadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ffn): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt = GPTModel(BASE_CONFIG)\n",
    "\n",
    "pretrained_state = torch.load(\"./ch05/gpt2-small-124m-pretrained.pth\", map_location=\"cpu\")\n",
    "gpt.load_state_dict(pretrained_state)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0725d785-d7b5-43a1-9800-49c12a19d4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.57\n",
      "Validation loss: 4.42\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, gpt, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, gpt, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.2f}\")\n",
    "print(f\"Validation loss: {val_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1178214-7968-4277-87df-62b45a3f3b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.489 Val loss 3.433\n",
      "Ep 1 (Step 000005): Train loss 1.943 Val loss 1.826\n",
      "Ep 1 (Step 000010): Train loss 1.111 Val loss 1.193\n",
      "Ep 1 (Step 000015): Train loss 1.069 Val loss 1.088\n",
      "Ep 1 (Step 000020): Train loss 0.964 Val loss 1.036\n",
      "Ep 1 (Step 000025): Train loss 0.911 Val loss 0.997\n",
      "Ep 1 (Step 000030): Train loss 0.940 Val loss 0.966\n",
      "Ep 1 (Step 000035): Train loss 0.853 Val loss 0.935\n",
      "Ep 1 (Step 000040): Train loss 0.825 Val loss 0.916\n",
      "Ep 1 (Step 000045): Train loss 0.747 Val loss 0.899\n",
      "Ep 1 (Step 000050): Train loss 0.845 Val loss 0.893\n",
      "Ep 1 (Step 000055): Train loss 0.907 Val loss 0.878\n",
      "Ep 1 (Step 000060): Train loss 0.853 Val loss 0.863\n",
      "Ep 1 (Step 000065): Train loss 0.774 Val loss 0.850\n",
      "Ep 1 (Step 000070): Train loss 0.677 Val loss 0.840\n",
      "Ep 1 (Step 000075): Train loss 0.688 Val loss 0.834\n",
      "Ep 1 (Step 000080): Train loss 0.733 Val loss 0.824\n",
      "Ep 1 (Step 000085): Train loss 0.667 Val loss 0.815\n",
      "Ep 1 (Step 000090): Train loss 0.711 Val loss 0.806\n",
      "Ep 1 (Step 000095): Train loss 0.640 Val loss 0.799\n",
      "Ep 1 (Step 000100): Train loss 0.622 Val loss 0.788\n",
      "Ep 1 (Step 000105): Train loss 0.712 Val loss 0.783\n",
      "Ep 1 (Step 000110): Train loss 0.698 Val loss 0.776\n",
      "Ep 1 (Step 000115): Train loss 0.654 Val loss 0.773\n",
      "Bellow is an instruction that describe a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an excerpt from the book, \"The Great American Novel: A Memoir.\"  The book is a memoir of the life of a young man who was\n",
      "Ep 2 (Step 000120): Train loss 0.576 Val loss 0.771\n",
      "Ep 2 (Step 000125): Train loss 0.604 Val loss 0.781\n",
      "Ep 2 (Step 000130): Train loss 0.566 Val loss 0.772\n",
      "Ep 2 (Step 000135): Train loss 0.531 Val loss 0.771\n",
      "Ep 2 (Step 000140): Train loss 0.566 Val loss 0.768\n",
      "Ep 2 (Step 000145): Train loss 0.501 Val loss 0.766\n",
      "Ep 2 (Step 000150): Train loss 0.502 Val loss 0.760\n",
      "Ep 2 (Step 000155): Train loss 0.577 Val loss 0.761\n",
      "Ep 2 (Step 000160): Train loss 0.570 Val loss 0.763\n",
      "Ep 2 (Step 000165): Train loss 0.523 Val loss 0.761\n",
      "Ep 2 (Step 000170): Train loss 0.431 Val loss 0.757\n",
      "Ep 2 (Step 000175): Train loss 0.468 Val loss 0.749\n",
      "Ep 2 (Step 000180): Train loss 0.519 Val loss 0.741\n",
      "Ep 2 (Step 000185): Train loss 0.549 Val loss 0.743\n",
      "Ep 2 (Step 000190): Train loss 0.428 Val loss 0.730\n",
      "Ep 2 (Step 000195): Train loss 0.451 Val loss 0.715\n",
      "Ep 2 (Step 000200): Train loss 0.395 Val loss 0.710\n",
      "Ep 2 (Step 000205): Train loss 0.462 Val loss 0.708\n",
      "Ep 2 (Step 000210): Train loss 0.504 Val loss 0.707\n",
      "Ep 2 (Step 000215): Train loss 0.517 Val loss 0.713\n",
      "Ep 2 (Step 000220): Train loss 0.400 Val loss 0.716\n",
      "Ep 2 (Step 000225): Train loss 0.472 Val loss 0.720\n",
      "Ep 2 (Step 000230): Train loss 0.414 Val loss 0.722\n",
      "Bellow is an instruction that describe a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an excerpt from the book 'The Great Gatsby': The Story of the Great Gatsby.  The Great Gatsby  The Great\n",
      "Training completed in 12.43 minutes.\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    "\n",
    "start_time = time.time()\n",
    "train_losses, val_losses, token_seen = train_model_simple(\n",
    "    gpt, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
    ")\n",
    "running_time_minutes = (time.time() - start_time) / 60\n",
    "print(f\"Training completed in {running_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e32d0b2-91a2-44bc-8985-2b58f7f2b32e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a2080-2826-476d-85d3-961a2d63a72a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
